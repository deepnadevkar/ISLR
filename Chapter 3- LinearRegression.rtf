{\rtf1\ansi\ansicpg1252\cocoartf1038\cocoasubrtf360
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
\margl1440\margr1440\vieww21400\viewh13440\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\ql\qnatural\pardirnatural

\f0\fs24 \cf0 Chapter 3: Linear Regression\
\
Conceptual Exercises Solutions\
\
1) Ho (TV): In the presence of radio and newspaper ads, TV ads have no effect on sales. REJECT  \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\ql\qnatural\pardirnatural
\cf0     Ho (radio): In the presence of TV and newspaper ads, radio ads have no effect on sales. REJECT\
    Ho (newspaper): In the presence of radio and TV ads, newspaper ads have no effect on sales. CANNOT REJECT\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\ql\qnatural\pardirnatural
\cf0 \
2) KNN classifier and KNN regression are very closely related when considering their mathematical derivations and formula. However, the difference lies in the final output result. For KNN classifier, the output for Y is qualitative, whereas for KNN regression, the output for Y is a quantitative value derived from f(x). \
\
3) Y = 50 + 20(GPA) + 0.07(IQ) + 35(gender) + 0.01(GPA * IQ) - 10 (GPA * gender)\
\
	(a) male: (gender = 0)    50 + 20(GPA) + 0.07(IQ) + 0.01(GPA * IQ)\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\ql\qnatural\pardirnatural
\cf0                   female: (gender = 1) 50 + 20(GPA) + 0.07 (IQ) + 35 + 0.01(GPA * IQ) - 10 (GPA)\outl\strokewidth60  \outl0\strokewidth0    \
                  If IQ and GPA are constant, the equation cancels out to 35-(10*GPA). So, once the GPA is high enough (> 3.5), males earn more on average. => iii.\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\ql\qnatural\pardirnatural
\cf0 \
	(b) Y(Gender = 1, IQ = 110, GPA = 4.0)\
	    = 50 + 20 * 4 + 0.07 * 110 + 35 + 0.01 (4 * 110) - 10 * 4\
	    = 137.1 (in thousands of $ = 137,100)\
\
	(c) False. We must examine the p-value of the regression coefficient to determine if the interaction term is statistically significant or not.\
4) \
	(a) The cubic regression may have a lower training RSS than the linear regression because it could make a tighter fit against data that resulted in a higher irreducible error (Var(epsilon)).\
\
	(b) In this case, the cubic regression may have a higher test RSS as the overfitting from training would have more error than the linear regression.\
\
	(c) As in (a), the cubic regression would have a lower training RSS than the linear fit because of higher flexibility. \
\
	(d) There is not enough information to tell which test RSS would be lower. If the true relationship is linear, then the linear regression test RSS could be lower than the cubic regression test RSS. 	If it is closer to cubic than linear, the cubic regression test RSS could be lower than the linear regression test RSS. \
\
5)???\
\
6) 	 y = B0 + B1 x \
from (3.4): B0 = mean(y) - B1* mean(x)\
\
Substitute, x for mean(x)\
\
y = mean(y)- B1*mean(x) + B1*mean(x)   \'85\'85..last two terms cancel So we are left with y = mean(y) when x = mean(x)\
\
\
}